# 효율적으로 챗봇 사용해보기(Efficient Chatbot Use)

신한 DS 금융 SW 아카데미 JDBC Project

## 프로젝트 소개

상용 LLM모델을 이용한 서비스 제작 시 효율적인 운영을 위한 백엔드 기능 개발

### 프로젝트 목적

#### 1) Chatbot memory

언어모델 자체에는 이전 대화내용을 기억하는 memory기능이 존재하지 않는다. 하지만 챗봇과의 원활한 대화를 위하여 DB에 로그를 저장하고 챗봇에 입력함으로써 memory기능을 구현해 본다.
  
#### 2) Reducing token 

언어모델의 입력과 출력은 token단위로 이루어진다. Prompt token이 많을수록 모델이 분석해야하는 데이터가 많아지며 complition token이 많아질 수록 답변의 길이가 길어진다. 즉 token의 양이 많아질수록 생성 속도는 늦어지고 비용이 늘어가게 된다. 따라서 서비스의 퀄리티가 유지되는 한에서 최대한 token 사용을 줄일 필요가 있다.  

- Cache 탐색
     
    사용자의 동일한 질문에 대하여 답변을 새로 생성하지 않고 log에서 조회하여 바로 답변하도록 구현.
     
- Summary 제작
  
    memory기능을 위하여 prompt에 이전 대화내용을 추가하다보면 굉장히 많은 token이 쌓이게 되므로 일정 token을 넘겼을 시 대화를 요약하여 데이터 량을 줄일 수 있도록 구현.

## 주요 기능

### 1. Chatbot memory

- #### Memory off
```
채팅을 종료하시려면 q또는 quit을 입력해 주세요.
user> 앞으로 말 끝에 냥을 붙여서 대답해
GPT> 알겠어냥! 질문이 있으면 언제든지 물어보라냥!
user> 안녕?
GPT> 안녕하세요! 무엇을 도와드릴까요?
```

```
Request01
Request: 앞으로 말 끝에 냥을 붙여서 대답해
Response: 알겠어냥! 질문이 있으면 언제든지 물어보라냥!

Request02
Request: 안녕?
Response: 안녕하세요! 무엇을 도와드릴까요?
```

- #### Memory on
```
채팅을 종료하시려면 q또는 quit을 입력해 주세요.
user> 앞으로 말 끝에 냥을 붙여서 대답해
GPT> 알겠어냥! 무엇을 도와드릴까냥?
user> 안녕?
GPT> 안녕하냥! 오늘을 기분이 어떠냥?
```

```
Request01
Request: 앞으로 말 끝에 냥을 붙여서 대답해
Response: 알겠어냥! 무엇을 도와드릴까냥?

Request02
Request: user> 앞으로 말 끝에 냥을 붙여서 대답해
         GPT> 알겠어냥! 무엇을 도와드릴까냥?
         user> 안녕?
Response: 알겠어냥! 무엇을 도와드릴까냥?
```
memory라고 해서 언어모델 자체에서 이전 내용을 기억하지는 못한다. 따라서 사용자의 입력에 이전 내용을 추가함으로써 챗봇이 마치 기억하는 것처럼 답변하도록 한다.





